# projectx_reference_crawler
projectxのリファレンスクローラー

Google Colab上でWebサイトクローラーを実行する方法
Google Colab上で差分検知機能付きのWebサイトクローラーを実行するためのノートブックを作成しました。このノートブックを使用することで、特別な環境構築なしにクローラーを実行できます。
利点

環境構築が不要 - 必要なライブラリはノートブック内でインストール
Google Driveとの連携 - キャッシュと出力ファイルを永続的に保存
使いやすいユーザーインターフェース - フォームやスライダーで簡単に設定可能
PDFサポート - 必要なwkhtmltopdfツールを自動インストール
差分検知機能 - 前回からの変更部分を自動検出してレポート

使用方法

ノートブック（website_crawler_colab.ipynb）をGoogle Colabにアップロードします
最初のセルを実行して必要なライブラリをインストールします
Google Driveをマウントします（キャッシュと出力の永続化のため）
コード定義セルを実行します
フォームでクロール対象のURLや設定を入力します
「クローラーを実行」ボタンをクリックしてクローラーを開始します

主な設定項目

URL: クロールを開始するWebサイトのURL
最大ページ数: クロールする最大ページ数
遅延時間: リクエスト間の待機時間（秒）
Discord Webhook URL: 通知先のWebhook URL（省略可）
差分検知: 前回からの変更を検出する機能の有効/無効
変更がない場合はスキップ: 前回から変更がない場合に処理をスキップ
出力ディレクトリ: 結果を保存するパス
キャッシュディレクトリ: キャッシュを保存するパス

注意点

Google Colabのセッションは一定時間で終了するため、長時間のクロールには適していません
大規模サイトのクロールは時間がかかるため、適切な最大ページ数を設定してください
定期的なクロールを行いたい場合は、ローカルマシンやサーバー環境での実行をお勧めします

ノートブックをColabで開いた後、各セルを順番に実行するだけで簡単にクローラーが使用できます！
